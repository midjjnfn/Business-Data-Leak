{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cce53a",
   "metadata": {},
   "source": [
    "# Company-Specific Autoencoders for Anomaly Detection on Scraped PDF Data\n",
    "\n",
    "This notebook implements and evaluates company-specific autoencoder models for detecting anomalous documents within a dataset of PDFs scraped from Scribd, pertaining to various Algerian companies.\n",
    "\n",
    "**Key Steps and Content:**\n",
    "\n",
    "* **Data Loading & Preprocessing:** Loads pre-computed SBERT embeddings for documents of multiple Algerian companies. For each company, its own documents are treated as \"normal\" data.\n",
    "* **Company-Specific Model Training:** Iterates through each company, training a dedicated autoencoder model using only that company's \"normal\" document embeddings. The autoencoder learns to reconstruct these normal embeddings with low error.\n",
    "* **Anomaly Injection for Evaluation:** For each company-specific model, \"anomalous\" documents are simulated by injecting a small number of documents from other companies into its validation and test sets.\n",
    "* **Threshold Optimization & Evaluation:** A Mean Squared Error (MSE) reconstruction threshold is determined for each model by maximizing the F1-score on its validation set. The model is then evaluated on its test set using metrics like F1-score, precision, recall, and a confusion matrix.\n",
    "* **Results Aggregation:** The performance metrics (threshold, F1, precision, recall, confusion matrix) for each company-specific model are collected and typically saved or displayed, forming the basis for Table 2.7 in the thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4247fe64",
   "metadata": {},
   "source": [
    "AADL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb754f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_AADL.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.2516 - val_loss: 0.2511\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2512 - val_loss: 0.2506\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2506 - val_loss: 0.2498\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.2498 - val_loss: 0.2486\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.2486 - val_loss: 0.2470\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.2469 - val_loss: 0.2447\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.2445 - val_loss: 0.2416\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.2413 - val_loss: 0.2376\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2371 - val_loss: 0.2324\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2318 - val_loss: 0.2257\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.2249 - val_loss: 0.2175\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.2164 - val_loss: 0.2073\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.2060 - val_loss: 0.1951\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1934 - val_loss: 0.1806\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1786 - val_loss: 0.1639\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1616 - val_loss: 0.1450\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.1426 - val_loss: 0.1245\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.1220 - val_loss: 0.1030\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.1006 - val_loss: 0.0815\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0795 - val_loss: 0.0614\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0599 - val_loss: 0.0439\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0431 - val_loss: 0.0298\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0296 - val_loss: 0.0194\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_AADL.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 0.2963\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.4000\n",
      "Precision  : 0.2917\n",
      "Recall     : 0.6364\n",
      "Confusion Matrix:\n",
      "[[12 17]\n",
      " [ 4  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.41      0.53        29\n",
      "         1.0       0.29      0.64      0.40        11\n",
      "\n",
      "    accuracy                           0.47        40\n",
      "   macro avg       0.52      0.53      0.47        40\n",
      "weighted avg       0.62      0.47      0.50        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_AADL.npy'\n",
    "\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    \n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    # 'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'   \n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))  ])\n",
    "\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0766b3a",
   "metadata": {},
   "source": [
    "air algerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3499172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Air_Algérie.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2515 - val_loss: 0.2509\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.2510 - val_loss: 0.2501\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2502 - val_loss: 0.2490\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.2490 - val_loss: 0.2473\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.2472 - val_loss: 0.2451\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.2448 - val_loss: 0.2421\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2415 - val_loss: 0.2382\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.2372 - val_loss: 0.2332\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.2316 - val_loss: 0.2270\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2247 - val_loss: 0.2192\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2161 - val_loss: 0.2098\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2057 - val_loss: 0.1986\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1933 - val_loss: 0.1855\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.1788 - val_loss: 0.1704\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1622 - val_loss: 0.1534\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.1437 - val_loss: 0.1347\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1236 - val_loss: 0.1148\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.1026 - val_loss: 0.0946\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0815 - val_loss: 0.0749\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0617 - val_loss: 0.0568\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0442 - val_loss: 0.0413\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0299 - val_loss: 0.0290\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Air_Algérie.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Best threshold: 0.001298\n",
      "Best F1 score (val): 0.5333\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.5926\n",
      "Precision  : 0.5000\n",
      "Recall     : 0.7273\n",
      "Confusion Matrix:\n",
      "[[0 8]\n",
      " [3 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.50      0.73      0.59        11\n",
      "\n",
      "    accuracy                           0.42        19\n",
      "   macro avg       0.25      0.36      0.30        19\n",
      "weighted avg       0.29      0.42      0.34        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Air_Algérie.npy'\n",
    "\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    \n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    # 'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'   \n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))  ])\n",
    "\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50043923",
   "metadata": {},
   "source": [
    "algerie poste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2de7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Algérie_Poste.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2516 - val_loss: 0.2511\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.2511 - val_loss: 0.2504\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2504 - val_loss: 0.2495\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2495 - val_loss: 0.2481\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2480 - val_loss: 0.2461\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.2459 - val_loss: 0.2433\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2431 - val_loss: 0.2395\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2391 - val_loss: 0.2345\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2340 - val_loss: 0.2281\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2273 - val_loss: 0.2198\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.2188 - val_loss: 0.2095\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2082 - val_loss: 0.1969\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1952 - val_loss: 0.1818\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1797 - val_loss: 0.1641\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.1617 - val_loss: 0.1441\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1413 - val_loss: 0.1220\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.1191 - val_loss: 0.0990\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.0960 - val_loss: 0.0761\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0734 - val_loss: 0.0550\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0529 - val_loss: 0.0372\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0357 - val_loss: 0.0234\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0227 - val_loss: 0.0140\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0138 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Algérie_Poste.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 0.3846\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.4324\n",
      "Precision  : 0.3077\n",
      "Recall     : 0.7273\n",
      "Confusion Matrix:\n",
      "[[ 5 18]\n",
      " [ 3  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.22      0.32        23\n",
      "         1.0       0.31      0.73      0.43        11\n",
      "\n",
      "    accuracy                           0.38        34\n",
      "   macro avg       0.47      0.47      0.38        34\n",
      "weighted avg       0.52      0.38      0.36        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Algérie_Poste.npy'\n",
    "\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    \n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    # 'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'   \n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))  ])\n",
    "\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b515c4",
   "metadata": {},
   "source": [
    "Algérie_Télécom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dbb3de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Algérie_Télécom.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.2516 - val_loss: 0.2510\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2510 - val_loss: 0.2502\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2502 - val_loss: 0.2490\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2491 - val_loss: 0.2472\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2474 - val_loss: 0.2447\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2451 - val_loss: 0.2413\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.2419 - val_loss: 0.2367\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2377 - val_loss: 0.2307\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.2321 - val_loss: 0.2231\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2251 - val_loss: 0.2134\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2162 - val_loss: 0.2014\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2052 - val_loss: 0.1870\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1920 - val_loss: 0.1700\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1763 - val_loss: 0.1504\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1582 - val_loss: 0.1287\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1379 - val_loss: 0.1054\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1159 - val_loss: 0.0819\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0934 - val_loss: 0.0597\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0715 - val_loss: 0.0404\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0518 - val_loss: 0.0253\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0354 - val_loss: 0.0147\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0230 - val_loss: 0.0081\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0143 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Algérie_Télécom.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Best threshold: 0.001301\n",
      "Best F1 score (val): 0.5556\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.7097\n",
      "Precision  : 0.5500\n",
      "Recall     : 1.0000\n",
      "Confusion Matrix:\n",
      "[[ 0  9]\n",
      " [ 0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.00      0.00      0.00         9\n",
      "     Anomaly       0.55      1.00      0.71        11\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.28      0.50      0.35        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rammo\\anaconda3\\envs\\AICS\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rammo\\anaconda3\\envs\\AICS\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\rammo\\anaconda3\\envs\\AICS\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Algérie_Télécom.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    # 'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae83ba",
   "metadata": {},
   "source": [
    "Crédit_Populaire_dAlgérie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d08c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Crédit_Populaire_dAlgérie.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.2516 - val_loss: 0.2511\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.2511 - val_loss: 0.2505\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2505 - val_loss: 0.2496\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2496 - val_loss: 0.2482\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.2483 - val_loss: 0.2462\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.2464 - val_loss: 0.2433\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.2436 - val_loss: 0.2394\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.2399 - val_loss: 0.2342\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2349 - val_loss: 0.2273\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.2284 - val_loss: 0.2185\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.2201 - val_loss: 0.2076\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2097 - val_loss: 0.1941\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1970 - val_loss: 0.1780\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1818 - val_loss: 0.1592\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1640 - val_loss: 0.1381\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1439 - val_loss: 0.1151\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1219 - val_loss: 0.0914\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0991 - val_loss: 0.0684\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0767 - val_loss: 0.0478\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0562 - val_loss: 0.0309\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0390 - val_loss: 0.0186\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0257 - val_loss: 0.0105\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0163 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0102 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Crédit_Populaire_dAlgérie.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 0.5000\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.3846\n",
      "Precision  : 0.3333\n",
      "Recall     : 0.4545\n",
      "Confusion Matrix:\n",
      "[[ 5 10]\n",
      " [ 6  5]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.45      0.33      0.38        15\n",
      "     Anomaly       0.33      0.45      0.38        11\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.39      0.39      0.38        26\n",
      "weighted avg       0.40      0.38      0.38        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Crédit_Populaire_dAlgérie.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    # 'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed31de",
   "metadata": {},
   "source": [
    "emploitic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd66f110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Emploitic.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2515 - val_loss: 0.2509\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2509 - val_loss: 0.2500\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2501 - val_loss: 0.2488\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.2489 - val_loss: 0.2469\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2470 - val_loss: 0.2444\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.2444 - val_loss: 0.2408\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.2409 - val_loss: 0.2362\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.2361 - val_loss: 0.2301\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2299 - val_loss: 0.2223\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2220 - val_loss: 0.2126\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.2121 - val_loss: 0.2007\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.1999 - val_loss: 0.1864\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.1853 - val_loss: 0.1696\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.1681 - val_loss: 0.1504\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.1486 - val_loss: 0.1292\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.1270 - val_loss: 0.1066\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1044 - val_loss: 0.0838\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0817 - val_loss: 0.0623\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0605 - val_loss: 0.0434\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0422 - val_loss: 0.0283\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0278 - val_loss: 0.0174\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0174 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Emploitic.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 0.7143\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.2857\n",
      "Precision  : 0.3000\n",
      "Recall     : 0.2727\n",
      "Confusion Matrix:\n",
      "[[5 7]\n",
      " [8 3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.38      0.42      0.40        12\n",
      "     Anomaly       0.30      0.27      0.29        11\n",
      "\n",
      "    accuracy                           0.35        23\n",
      "   macro avg       0.34      0.34      0.34        23\n",
      "weighted avg       0.34      0.35      0.35        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Emploitic.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    # 'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7d0e6",
   "metadata": {},
   "source": [
    "icosnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fafc40de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_ICOSNET.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2514 - val_loss: 0.2509\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.2509 - val_loss: 0.2502\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.2502 - val_loss: 0.2491\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.2491 - val_loss: 0.2477\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 0.2474 - val_loss: 0.2455\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2451 - val_loss: 0.2426\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2418 - val_loss: 0.2388\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2375 - val_loss: 0.2337\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2318 - val_loss: 0.2273\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.2244 - val_loss: 0.2190\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.2151 - val_loss: 0.2089\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2035 - val_loss: 0.1964\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1894 - val_loss: 0.1815\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1726 - val_loss: 0.1641\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.1533 - val_loss: 0.1442\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1316 - val_loss: 0.1225\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1084 - val_loss: 0.0997\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0848 - val_loss: 0.0771\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0625 - val_loss: 0.0563\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0430 - val_loss: 0.0387\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0275 - val_loss: 0.0250\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0165 - val_loss: 0.0154\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_ICOSNET.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 0.7273\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.8182\n",
      "Precision  : 0.8182\n",
      "Recall     : 0.8182\n",
      "Confusion Matrix:\n",
      "[[3 2]\n",
      " [2 9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.60      0.60      0.60         5\n",
      "     Anomaly       0.82      0.82      0.82        11\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.71      0.71      0.71        16\n",
      "weighted avg       0.75      0.75      0.75        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_ICOSNET.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    # 'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d00b25",
   "metadata": {},
   "source": [
    "ooredoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe1f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Ooredoo.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2516 - val_loss: 0.2511\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2511 - val_loss: 0.2505\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2505 - val_loss: 0.2495\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.2495 - val_loss: 0.2480\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2481 - val_loss: 0.2459\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2460 - val_loss: 0.2430\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.2431 - val_loss: 0.2391\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.2392 - val_loss: 0.2340\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2340 - val_loss: 0.2275\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.2274 - val_loss: 0.2192\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2190 - val_loss: 0.2089\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2086 - val_loss: 0.1964\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1959 - val_loss: 0.1814\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.1808 - val_loss: 0.1640\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1632 - val_loss: 0.1444\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.1434 - val_loss: 0.1229\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.1218 - val_loss: 0.1006\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0993 - val_loss: 0.0784\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0772 - val_loss: 0.0579\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0568 - val_loss: 0.0403\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0394 - val_loss: 0.0265\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0259 - val_loss: 0.0166\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0163 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Ooredoo.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Best threshold: 0.001301\n",
      "Best F1 score (val): 0.5556\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.5714\n",
      "Precision  : 0.4706\n",
      "Recall     : 0.7273\n",
      "Confusion Matrix:\n",
      "[[0 9]\n",
      " [3 8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.00      0.00      0.00         9\n",
      "     Anomaly       0.47      0.73      0.57        11\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.24      0.36      0.29        20\n",
      "weighted avg       0.26      0.40      0.31        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Ooredoo.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    # 'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc773c6",
   "metadata": {},
   "source": [
    "oudkniss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c48507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Ouedkniss.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.2516 - val_loss: 0.2510\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.2511 - val_loss: 0.2503\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2505 - val_loss: 0.2494\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.2497 - val_loss: 0.2482\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.2484 - val_loss: 0.2464\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.2467 - val_loss: 0.2439\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2442 - val_loss: 0.2406\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2410 - val_loss: 0.2362\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2366 - val_loss: 0.2305\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.2309 - val_loss: 0.2232\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.2236 - val_loss: 0.2141\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.2144 - val_loss: 0.2028\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2030 - val_loss: 0.1892\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1891 - val_loss: 0.1730\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1727 - val_loss: 0.1544\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.1536 - val_loss: 0.1336\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1323 - val_loss: 0.1112\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.1094 - val_loss: 0.0884\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 0.0861 - val_loss: 0.0665\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0637 - val_loss: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0441 - val_loss: 0.0310\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0285 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Ouedkniss.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 1.0000\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.6000\n",
      "Precision  : 0.6667\n",
      "Recall     : 0.5455\n",
      "Confusion Matrix:\n",
      "[[7 3]\n",
      " [5 6]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.58      0.70      0.64        10\n",
      "     Anomaly       0.67      0.55      0.60        11\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.62      0.62      0.62        21\n",
      "weighted avg       0.63      0.62      0.62        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Ouedkniss.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d7eba",
   "metadata": {},
   "source": [
    "Sonelgaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "430a9b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Sonelgaz.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2516 - val_loss: 0.2511\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2511 - val_loss: 0.2505\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2504 - val_loss: 0.2495\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2495 - val_loss: 0.2482\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2481 - val_loss: 0.2463\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 0.2462 - val_loss: 0.2437\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.2435 - val_loss: 0.2403\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2399 - val_loss: 0.2359\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2352 - val_loss: 0.2303\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2292 - val_loss: 0.2232\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2215 - val_loss: 0.2144\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.2121 - val_loss: 0.2038\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2005 - val_loss: 0.1910\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1868 - val_loss: 0.1760\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1707 - val_loss: 0.1588\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1524 - val_loss: 0.1396\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1322 - val_loss: 0.1189\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.1107 - val_loss: 0.0974\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0888 - val_loss: 0.0762\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0677 - val_loss: 0.0565\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0489 - val_loss: 0.0397\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0333 - val_loss: 0.0264\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0215 - val_loss: 0.0167\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Sonelgaz.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Best threshold: 0.001301\n",
      "Best F1 score (val): 0.5000\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.5517\n",
      "Precision  : 0.4444\n",
      "Recall     : 0.7273\n",
      "Confusion Matrix:\n",
      "[[ 0 10]\n",
      " [ 3  8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.00      0.00      0.00        10\n",
      "     Anomaly       0.44      0.73      0.55        11\n",
      "\n",
      "    accuracy                           0.38        21\n",
      "   macro avg       0.22      0.36      0.28        21\n",
      "weighted avg       0.23      0.38      0.29        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Sonelgaz.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "  \n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Append additional anomalies to test set\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1563df",
   "metadata": {},
   "source": [
    "sonatrach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec75a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Sonatrach.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2516 - val_loss: 0.2510\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.2510 - val_loss: 0.2503\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.2503 - val_loss: 0.2493\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2492 - val_loss: 0.2478\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.2476 - val_loss: 0.2457\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2453 - val_loss: 0.2427\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.2420 - val_loss: 0.2387\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2377 - val_loss: 0.2335\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2320 - val_loss: 0.2267\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2248 - val_loss: 0.2182\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2157 - val_loss: 0.2077\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2044 - val_loss: 0.1949\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.1908 - val_loss: 0.1797\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1747 - val_loss: 0.1621\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1562 - val_loss: 0.1422\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1354 - val_loss: 0.1205\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1132 - val_loss: 0.0980\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0904 - val_loss: 0.0759\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0684 - val_loss: 0.0555\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0488 - val_loss: 0.0381\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0327 - val_loss: 0.0247\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0207 - val_loss: 0.0151\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Sonatrach.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Best threshold: 0.001301\n",
      "Best F1 score (val): 0.4000\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score =  0.625\n",
      "recall_score Score =  0.9090909090909091\n",
      "precision_score Score =  0.47619047619047616\n",
      "Confusion Matrix:\n",
      "[[ 0 11]\n",
      " [ 1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.00      0.00      0.00        11\n",
      "     Anomaly       0.48      0.91      0.62        11\n",
      "\n",
      "    accuracy                           0.45        22\n",
      "   macro avg       0.24      0.45      0.31        22\n",
      "weighted avg       0.24      0.45      0.31        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Sonatrach.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    # # Skip empty files or corrupted embeddings\n",
    "    # if embeddings.size == 0:\n",
    "    #     print(f\"Skipping {filename} (empty)\")\n",
    "    #     continue\n",
    "\n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# # Append additional anomalies to test set\n",
    "# X_test = np.concatenate([X_test-anomaly_embeddings, anomaly_embeddings_2], axis=0)\n",
    "# y_test = np.concatenate([y_test, np.ones(len(anomaly_embeddings_2))], axis=0)\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# Keep only normal samples in test set\n",
    "\n",
    "\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score = \", f1_score(y_test, y_pred_test))\n",
    "print(f\"recall_score Score = \", recall_score(y_test, y_pred_test))\n",
    "print(f\"precision_score Score = \", precision_score(y_test, y_pred_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Anomaly']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7aa15b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.0, 10.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum(), len(y_test)-y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7405d119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 5, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb1c19",
   "metadata": {},
   "source": [
    "yassir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cee66c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Yassir.npy...\n",
      "Training new autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2515 - val_loss: 0.2510\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2509 - val_loss: 0.2502\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2501 - val_loss: 0.2492\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2488 - val_loss: 0.2477\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.2470 - val_loss: 0.2457\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2445 - val_loss: 0.2429\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2411 - val_loss: 0.2393\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.2367 - val_loss: 0.2347\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2310 - val_loss: 0.2289\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2239 - val_loss: 0.2217\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.2150 - val_loss: 0.2130\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2042 - val_loss: 0.2024\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1913 - val_loss: 0.1898\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1762 - val_loss: 0.1752\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.1587 - val_loss: 0.1586\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1393 - val_loss: 0.1401\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1183 - val_loss: 0.1201\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0966 - val_loss: 0.0995\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0753 - val_loss: 0.0792\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0558 - val_loss: 0.0603\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0393 - val_loss: 0.0439\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0262 - val_loss: 0.0307\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0169 - val_loss: 0.0206\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Saved model  to C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2\\model_all_docs_v2_test_Yassir.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Best threshold: 0.001302\n",
      "Best F1 score (val): 0.6667\n",
      "\n",
      "Test Evaluation:\n",
      "F1 Score   : 0.6923\n",
      "Precision  : 0.6000\n",
      "Recall     : 0.8182\n",
      "Confusion Matrix:\n",
      "[[1 6]\n",
      " [2 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.14      0.20         7\n",
      "         1.0       0.60      0.82      0.69        11\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.47      0.48      0.45        18\n",
      "weighted avg       0.50      0.56      0.50        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder containing embeddings\n",
    "folder_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_file ='C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/documents and embeddings/all_docs_v2_test_Yassir.npy'\n",
    "\n",
    "# for filename in embedding_files:\n",
    "filename_only = os.path.basename(embedding_file)  # Gives: all_docs_v2_test_Sonelgaz.npy\n",
    "model_name = f\"model_{filename_only.replace('.npy', '')}.keras\"\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "print(f\"Processing {embedding_file}...\")\n",
    "    \n",
    "    # Load embeddings\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "    \n",
    "# Split embeddings: 80% for training, 20% for normal test\n",
    "x_train, x_test_normal = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========== MODEL SETUP ==========\n",
    "input_dim = x_train.shape[1]\n",
    "encoder_input = Input(shape=(input_dim,))\n",
    "x = Dense(256, activation='relu')(encoder_input)\n",
    "encoded = Dense(32, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "autoencoder = Model(encoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ========== TRAIN MODEL IF NOT EXIST ==========\n",
    "\n",
    "print(\"Training new autoencoder...\")\n",
    "autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved model  to {model_path}\")\n",
    "\n",
    "# ========== ANOMALY EMBEDDINGS ==========\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy',\n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonelgaz.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[0:1] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(os.path.join(folder_path, src))[1:2] for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# ========== TEST SET CONSTRUCTION ==========\n",
    "X_tmp = np.concatenate([x_test_normal, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(x_test_normal)),  # normal\n",
    "    np.ones(len(anomaly_embeddings))  # anomaly\n",
    "])\n",
    "\n",
    "# Split into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "X_test_normal_only = X_test[y_test == 0]\n",
    "y_test_normal_only = y_test[y_test == 0]  \n",
    "\n",
    "# Step 4: Append new anomalies to test set\n",
    "X_test = np.concatenate([X_test_normal_only, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([\n",
    "    y_test_normal_only,                      # normal (0s)\n",
    "    np.ones(len(anomaly_embeddings_2))       # new anomalies (1s)\n",
    "])\n",
    "# ========== PREDICTIONS ==========\n",
    "recon_val = autoencoder.predict(X_val)\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# ========== THRESHOLD SELECTION ==========\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    preds = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, preds))\n",
    "\n",
    "best_thresh = sorted_mse[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {max(f1_scores):.4f}\")\n",
    "\n",
    "# ========== FINAL EVALUATION ==========\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision  : {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall     : {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af321b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32995aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "2\n",
      "2\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test_normal))\n",
    "print(len(anomaly_embeddings))\n",
    "print(len(anomaly_embeddings_2))\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to folder containing embeddings\n",
    "folder_path = '/content/drive/MyDrive/documents'\n",
    "\n",
    "# Filter for .npy files\n",
    "embedding_files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
    "\n",
    "for filename in embedding_files:\n",
    "    npy_path = os.path.join(folder_path, filename)\n",
    "    model_name = f\"model_{filename.replace('.npy', '')}.weights.h5\"\n",
    "    model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "    print(f\"Processing {filename}...\")\n",
    "\n",
    "    # Load embeddings\n",
    "    embeddings = np.load(npy_path)\n",
    "\n",
    "    # Skip empty files or corrupted embeddings\n",
    "    if embeddings.size == 0:\n",
    "        print(f\"Skipping {filename} (empty)\")\n",
    "        continue\n",
    "\n",
    "    with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):\n",
    "        x_train = embeddings\n",
    "        input_dim = x_train.shape[1]\n",
    "\n",
    "        # Build autoencoder\n",
    "        encoder_input = Input(shape=(input_dim,))\n",
    "        x = Dense(256, activation='relu')(encoder_input)\n",
    "        encoded = Dense(32, activation='relu')(x)\n",
    "        x = Dense(256, activation='relu')(encoded)\n",
    "        decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "        autoencoder = Model(encoder_input, decoded)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # Train\n",
    "        autoencoder.fit(\n",
    "            x_train, x_train,\n",
    "            epochs=50,\n",
    "            batch_size=256,\n",
    "            shuffle=True,\n",
    "            validation_split=0.1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "\n",
    "        # Save model\n",
    "        autoencoder.save_weights(model_path, overwrite=True)\n",
    "        print(f\"Saved model to {model_path}\")\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_path = 'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2/Sonelgaz.keras'\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Load embeddings\n",
    "normal_embeddings = np.load('C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2/all_docs_v2_test_Sonelgaz.npy')\n",
    "\n",
    "anomaly_sources = [\n",
    "    'all_docs_v2_test_AADL.npy',\n",
    "    'all_docs_v2_test_Air_Algérie.npy',\n",
    "    'all_docs_v2_test_Algérie_Poste.npy',\n",
    "    'all_docs_v2_test_Algérie_Télécom.npy', \n",
    "    'all_docs_v2_test_Crédit_Populaire_dAlgérie.npy',\n",
    "    'all_docs_v2_test_Emploitic.npy',\n",
    "    'all_docs_v2_test_ICOSNET.npy',\n",
    "    'all_docs_v2_test_Ooredoo.npy',\n",
    "    'all_docs_v2_test_Ouedkniss.npy',\n",
    "    'all_docs_v2_test_Sonatrach.npy',\n",
    "    'all_docs_v2_test_Yassir.npy'\n",
    "]\n",
    "\n",
    "anomaly_embeddings = np.concatenate([\n",
    "    np.load(f'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2/{src}')[0:2]\n",
    "    for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "# Create labels\n",
    "X = np.concatenate([normal_embeddings, anomaly_embeddings], axis=0)\n",
    "y = np.zeros(len(normal_embeddings))\n",
    "\n",
    "# Train/val/test split\n",
    "# Step 1: Split normal embeddings\n",
    "_, X_tmp = train_test_split(normal_embeddings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Add anomalies for evaluation\n",
    "X_tmp = np.concatenate([X_tmp, anomaly_embeddings], axis=0)\n",
    "y_tmp = np.concatenate([\n",
    "    np.zeros(len(X_tmp) - len(anomaly_embeddings)),np.ones(len(anomaly_embeddings))], axis=0)\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
    ")\n",
    "\n",
    "# Instead of slicing out normal samples, just append additional anomalies\n",
    "anomaly_embeddings_2 = np.concatenate([\n",
    "    np.load(f'C:/Users/rammo/Desktop/Data sensitivity discovery/Anomaly Detection in docs/Scaping dataset/scribd_test_2/{src}')[2:4]\n",
    "    for src in anomaly_sources\n",
    "], axis=0)\n",
    "\n",
    "X_test = np.concatenate([X_test, anomaly_embeddings_2], axis=0)\n",
    "y_test = np.concatenate([y_test, np.ones(len(anomaly_embeddings_2))], axis=0)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "recon_val = model.predict(X_val)\n",
    "recon_test = model.predict(X_test)\n",
    "mse_val = np.mean(np.square(X_val - recon_val), axis=1)\n",
    "mse_test = np.mean(np.square(X_test - recon_test), axis=1)\n",
    "\n",
    "# Find optimal threshold\n",
    "sorted_mse = np.sort(mse_val)\n",
    "f1_scores = []\n",
    "for thresh in sorted_mse:\n",
    "    y_pred_val = (mse_val > thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, y_pred_val))\n",
    "\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_thresh = sorted_mse[best_idx]\n",
    "print(f\"Best threshold: {best_thresh:.6f}\")\n",
    "print(f\"Best F1 score (val): {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# Test evaluation\n",
    "y_pred_test = (mse_test > best_thresh).astype(int)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nTest Evaluation:\")\n",
    "print(f\"F1 Score   : {f1:.4f}\")\n",
    "print(f\"Precision  : {precision:.4f}\")\n",
    "print(f\"Recall     : {recall:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AICS)",
   "language": "python",
   "name": "aics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
